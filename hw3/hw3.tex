\documentclass{article}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{url}
\usepackage{color}
% \usepackage{savetrees}
\usepackage{listings}
% \usetikzlibrary{shapes}

% pseudocode notations
\newcommand{\xif}{{\bf{\em{if~}}}}
\newcommand{\xthen}{{\bf{\em{then~}}}}
\newcommand{\xelse}{{\bf{\em{else~}}}}
\newcommand{\xelseif}{{\bf{\em{elif~}}}}
\newcommand{\xfi}{{\bf{\em{fi~}}}}
\newcommand{\xcase}{{\bf{\em{case~}}}}
\newcommand{\xendcase}{{\bf{\em{endcase~}}}}
\newcommand{\xfor}{{\bf{\em{for~}}}}
\newcommand{\xto}{{\bf{\em{to~}}}}
\newcommand{\xby}{{\bf{\em{by~}}}}
\newcommand{\xdownto}{{\bf{\em{downto~}}}}
\newcommand{\xdo}{{\bf{\em{do~}}}}
\newcommand{\xrof}{{\bf{\em{rof~}}}}
\newcommand{\xwhile}{{\bf{\em{while~}}}}
\newcommand{\xendwhile}{{\bf{\em{endwhile~}}}}
\newcommand{\xand}{{\bf{\em{and~}}}}
\newcommand{\xor}{{\bf{\em{or~}}}}
\newcommand{\xerror}{{\bf{\em{error~}}}}
\newcommand{\xreturn}{{\bf{\em{return~}}}}
\newcommand{\xparallel}{{\bf{\em{parallel~}}}}
\newcommand{\T}{\hspace{0.5cm}}
\newcommand{\m}{\mathcal}

\def\func#1{\textrm{\bf{\sc{#1}}}}
\def\funcbf#1{\textrm{\textbf{\textsc{#1}}}}


\linespread{1.5}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.9ex plus 0.5ex minus 0.2ex}

% \linespread{1.4}

\title{CSE613\\Parallel Programming -- Homework-3}

\author{Dhruv Matani (108267786) \& Gaurav Menghani (108266803)}

\renewcommand{\thesubsection}{\thesection\ (\alph{subsection})}

\begin{document}
\maketitle

\clearpage

\tableofcontents

\clearpage

\section{Shared Memory Quicksort}

\subsection{Best base case for part(c)}

\begin{center}
  \begin{tabular}{| l | r | r | r | r | r | r | r | r | r |}
    \hline
    Base Case (\# of elements) & 4 & 16 & 32 & 64 & 128 & 512 & 1024 & 4096 & 8192 \\ \hline
    Running time (second) & 50 & 40 & 39 & 37 & 32 & 33 & 36 & 30 & 35 \\ \hline
  \end{tabular}
\end{center}

We can see that the best running time is with a base case of \texttt{4096} elements.

\subsection{Parallel Quicksort from part(c) when run on a single core and on all cores}

\begin{center}
  \begin{tabular}{| l | r | r | r | r | r | r |}
    \hline
    Test \# & 01 & 02 & 03 & 04 & 05 & 06 \\ \hline
    Serial (sec)           & 0.32 & 5.08 & 33.08 & 39.93 & 58.12 & 69.56 \\ \hline
    Parallel (sec)/speedup & 0.21/35\% & 3.08/39\% & 16.56/50\% & 17.28/57\% & 21.40/63\% & 42.39/39\% \\ \hline
  \end{tabular}
\end{center}

\subsection{Parallel Quicksort with Serial Partition}

\begin{center}
  \begin{tabular}{| l | r | r | r | r | r | r | r | r | r |}
    \hline
    Base Case (\# of elements) & 4 & 16 & 32 & 64 & 128 & 512 & 1024 & 4096 & 8192 \\ \hline
    Parallel Partition (sec) & 50 & 40 & 39 & 37 & 32 & 33 & 36 & 30 & 35 \\ \hline
    Serial Partition (sec) & 49 & 40 & 38 & 33 & 35 & 31 & 30 & 32 & 38 \\ \hline
  \end{tabular}
\end{center}


\section{Distributed Sample Sort with Shared-Memory QuickSort}

\subsection{Each process sorts $\frac{n}{p}$ + $\frac{n}{q}$ keys in worst case}
In step 1, we distribute the $n$ keys evenly 
(as evenly as possible) between $p$ processes. Thus, each 
process has a chunk of $\frac{n}{p}$ (roughly) keys.

During step 2, each process has $q-1$ local pivots, which pivot 
the $\frac{n}{p}$ keys of the process evenly. Thus each local 
pivot has about $\frac{n}{pq}$ elements to its either side. 

There are $p$ global pivots out of the total $p(q-1)$ local pivots.
Each global pivot has $q-1$ local pivots to its either side. In
the worst case, all the $q-1$ pivots of the first chunk are the
smallest. This means, that the first global pivot is bigger than
all the pivots from the first chunk. In addition, all the 
$\frac{n}{p}$ keys in the first chunk might be smaller than the 
first pivot, and thus would be with the same process.

Now, the first global pivot selected would be the first local
pivot of one of the remaining $p-1$ processes. Now, in the worst
case, all the $\frac{n}{pq}$ elements in each of the processes, 
which lie to the left of the first local pivots in the chunks
of those processes,
except the first one, might be less than the first global pivot,
and hence would all go to the first process. The total keys
that would go to the first process would be $(p-1) \times 
\frac{n}{pq}$ which is in the worst case $\frac{n}{q}$.

Therefore, in all, the total number of keys with the first
process, in the worst case, would be, $\frac{n}{p} + \frac{n}{q}$.
Hence, proved.

\subsection{Implementation of the Algorithm}

\subsection{Communication \& Computation Complexities}
The communication and computation costs can be accounted for, as
follows:

The communication cost can be accounted for, as follows (we assume
$q = \Theta(p)$):
\begin{enumerate}
\item Initial Distribution: $n$ keys are evenly distributed to 
$p$ processes. So each process receives at max 
$\lceil\frac{n}{p}\rceil$ keys, and therefore, the communication 
cost  (for sending to $p$ processes) is $p \times O(\frac{n}{p}) =$
$ O(n)$.
\item Pivot Selection: The master receives $q-1$ local pivots from 
each of the $p$ processes, and sends $p-1$ global pivots to each 
of the processes. This costs $O(p^2) + O((p-1)\log{p})$.  
\item Local Bucketing: This stage has no communication cost.
\item Distribute Local Buckets: $O(n)$.
\item Local Sort: This stage has no communication cost.
\item Final Collection: We would be collecting $n$ keys, therefore,
the cost of communication is $O(n)$.
\end{enumerate}
Therefore, the total cost of communication would be: 
$t_{comm} = O(n + p^2)$.

Now, we can find out the computation complexity as follows:
\begin{enumerate}
\item Initial Distribution: There is no computational cost at this stage.
\item Pivot Selection: 
  \begin{enumerate}
  \item Local Sorting of chunks of size $\lceil\frac{n}{p}\rceil$ costs: $O(\frac{n}{p}\log{\frac{n}{p}})$.   
  \item Selection of Local Pivot \& Sending them to the Master 
  Process: Each process would select $q-1$ pivots and send to 
  the master process, therefore, the total cost would be $O(p^2)$.
  \item Sorting of the Accumulated Local Pivots: There are $p(q-1) 
  = O(p^2)$ pivots in all, and hence the sorting of the 
  accumulated local pivots would be $O(p^2\log{p})$.
  \item Selection \& Broadcasting of Global Pivots: There is no
  computational cost at this stage.
  \end{enumerate}
\item Local Bucketing: Each process tries to insert the $p-1$ 
global pivots it received from the master into the sorted set of 
$\frac{n}{p}$ keys that it already has, using Binary Search. 
This costs $O(p\log{\frac{n}{p}})$.
\item Distribute Local Buckets: Each process sends $p-1$ of its
buckets to other processes. Therefore, the total complexity is
$O(p^2)$.
\item Local Sort: Each process has about $\frac{n}{p}$ keys
with itself, and sorting them locally takes 
$O(\frac{n}{p}\log{\frac{n}{p}})$ time. 
\item Final Collection: Final merging of the buckets is $O(n)$.
\end{enumerate}
Therefore, the total computation cost is: 
$t_{comp} = O\left(p + \dfrac{n}{p}\log{\dfrac{n}{p}} + 
p^2\log{p} + p\log{\dfrac{n}{p}} + n\right)$.

The total cost $T_P = t_{comm} + t_{comp}$. 
$\Rightarrow T_P = O(n + p^2)$ +  
$ O\left(p + \dfrac{n}{p}\log{\dfrac{n}{p}} + 
p^2\log{p} + p\log{\dfrac{n}{p}} + n\right)$ 
\subsection{Value of $k$ that gives best running time is: 4}

The value of $k$ that gives us the best running time is $4$.

\subsection{Report Running Times}

Running time (in second) with all steps included:

\begin{center}
  \begin{tabular}{| l | r | r | r | r | r | r |}
    \hline
    Test Case \# & 01 & 02 & 03 & 04 & 05 & 06  \\ \hline
    1 Process/node & 3.53 & 26.93 & 238.48 & 241.67 & 324.14 & 391.85 \\ \hline
    2 Processes/node & 2.63 & 20.86 & 150.53 & 205.04 & 343.98 &  \\ \hline
    6 Processes/node & 3.43 & 39.14 & 191.56 & 236.99 & 292.40 & 180.42 \\ \hline
    12 Processes/node & 1.66 & 38.85 & 106.76 & 259.94 & 218.19 & 356.61 \\ \hline
  \end{tabular}
\end{center}


Running time excluding steps 1 \& 6:

\begin{center}
  \begin{tabular}{| l | r | r | r | r | r | r |}
    \hline
    Test Case \# & 01 & 02 & 03 & 04 & 05 & 06  \\ \hline
    1 Process/node & 3.52 & 16.80 & 238.28 & 177.96 & 323.68 & 390.97 \\ \hline
    2 Processes/node & 1.61 & 16.05 & 150.00 & 204.51 & 343.65 &  \\ \hline
    6 Processes/node & 3.42 & 39.07 & 191.03 & 236.55 & 291.59 & 178.83 \\ \hline
    12 Processes/node & 0.41 & 38.78 & 15.53 & 259.44 & 94.41 & 100.58 \\ \hline
  \end{tabular}
\end{center}

\end{document}
